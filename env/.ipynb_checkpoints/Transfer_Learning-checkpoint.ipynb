{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(vgg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image = load_img('../img/mug.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x1B600256898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for the model\n",
    "image = image.reshape(\n",
    "    (1, image.shape[0], image.shape[1], image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "       [[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "y_pred = vgg.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1224267e-08, 7.7827941e-08, 9.1825092e-10], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0, :3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: coffee_mug, proba 62.75%\n"
     ]
    }
   ],
   "source": [
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(y_pred)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print(\"class: {}, proba {:.2f}%\".format(label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n03063599', 'coffee_mug', 0.6274737),\n",
       "  ('n07930864', 'cup', 0.30253103),\n",
       "  ('n03950228', 'pitcher', 0.018699935),\n",
       "  ('n03733805', 'measuring_cup', 0.015958836),\n",
       "  ('n07920052', 'espresso', 0.0070127705)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_predictions(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette fonction fait la même chose que les cellules précédentes,\n",
    "# mais en version plus propre\n",
    "\n",
    "def predict_image_using_vgg(img_path, vgg):\n",
    "    \"\"\"\n",
    "    Open image, convert it to an array, and run predictions\n",
    "    using a trained model.\n",
    "    \"\"\"\n",
    "    # load an image from file\n",
    "    image = load_img(img_path, target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for the model\n",
    "    image = image.reshape(\n",
    "        (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    y_pred = vgg.predict(image)\n",
    "    labels = decode_predictions(y_pred)\n",
    "    label = labels[0][0]\n",
    "    print(\"class: {}, proba {:.2f}%\".format(label[1], label[2]*100))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: coffee_mug, proba 62.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n03063599', 'coffee_mug', 0.6274737),\n",
       "  ('n07930864', 'cup', 0.30253103),\n",
       "  ('n03950228', 'pitcher', 0.018699935),\n",
       "  ('n03733805', 'measuring_cup', 0.015958836),\n",
       "  ('n07920052', 'espresso', 0.0070127705)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image_using_vgg('../img/mug.jpg', vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '../img/logos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9edf8ff42d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../img/logos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../img/logos/{}/*'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '../img/logos'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "all_images = []\n",
    "image_arrays = []\n",
    "all_labels = []\n",
    "filenames = []\n",
    "for class_id, label in enumerate(os.listdir('../img/animaux')):\n",
    "    print(class_id, label)\n",
    "    for filename in glob.glob('../img/animaux/{}/*'.format(label)):\n",
    "        filenames.append(filename)\n",
    "        im = load_img(filename, target_size=(224, 224))\n",
    "        all_images.append(im)\n",
    "        preprocessed = preprocess_input(img_to_array(im))\n",
    "        image_arrays.append(preprocessed)\n",
    "        all_labels.append(class_id)\n",
    "X = np.array(image_arrays)\n",
    "Y = to_categorical(np.array(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: refator this function, \"def create_dataset(folder): .... return X, Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(folder):\n",
    "    all_images = []\n",
    "    image_arrays = []\n",
    "    all_labels = []\n",
    "    filenames = []\n",
    "    for class_id, label in enumerate(os.listdir(folder)):\n",
    "        print(class_id, label)\n",
    "        for filename in glob.glob(folder+'/{}/*'.format(label)):\n",
    "            filenames.append(filename)\n",
    "            im = load_img(filename, target_size=(224, 224))\n",
    "            all_images.append(im)\n",
    "            preprocessed = preprocess_input(img_to_array(im))\n",
    "            image_arrays.append(preprocessed)\n",
    "            all_labels.append(class_id)\n",
    "    X = np.array(image_arrays)\n",
    "    Y = to_categorical(np.array(all_labels))\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_images), len(all_labels), len(image_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 11\n",
    "predict_image_using_vgg(filenames[img_id], vgg)\n",
    "all_images[img_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VGG16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2a61158eccb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Charger VGG-16 pré-entraîné sur ImageNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# mais sans les couches fully-connected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m vgg_cut = VGG16(weights=\"imagenet\", include_top=False,\n\u001b[0m\u001b[0;32m      4\u001b[0m                 input_shape=(224, 224, 3))\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg_cut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VGG16' is not defined"
     ]
    }
   ],
   "source": [
    "# Charger VGG-16 pré-entraîné sur ImageNet\n",
    "# mais sans les couches fully-connected\n",
    "vgg_cut = VGG16(weights=\"imagenet\", include_top=False,\n",
    "                input_shape=(224, 224, 3))\n",
    "x = vgg_cut.output\n",
    "# transform matrix into 1-d vector\n",
    "x = Flatten()(x)\n",
    "x = Dense(30, activation='relu')(x) \n",
    "x = Dense(9, activation='softmax')(x)  \n",
    "\n",
    "# TODO parametrer le nombre de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Model(inputs=vgg_cut.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratégie de Transfer Learning: extraction de features\n",
    "# On entraîne seulement le nouveau classifieur,\n",
    "# et on ne ré-entraîne pas les autres couches.\n",
    "# On utilise les autres couches uniquement pour \n",
    "# extraire des features des images\n",
    "for layer in custom_model.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "custom_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner sur toutes les données\n",
    "# (X_train, Y_train)\n",
    "custom_model.fit(X, Y,\n",
    "                 epochs=3, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisons notre modèle entrainé pour faire des prédiction sur les images de test\n",
    "#### TODO! écrire le code qui charge des photos du nouveau dossier, img_test, qui n'a pas été utilisé pour l'entrainement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher l'image\n",
    "(X_test,Y_test) = create_data_set(testfolder)   \n",
    "array_to_img(X_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.predict(X_test[5].reshape(1, *X_test[5].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vraie valeur (\"bonne réponse\")\n",
    "Y_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet\n",
    "1. Trouver le sujet de classification d'images\n",
    "2. Créer le jeu de données:\n",
    "    * Télécharger les images de l'Internet\n",
    "    * Utiliser le plugin de navigateur pour aller plus vite:\n",
    "    * Saisir la requete sur Google Images (par exemple)\n",
    "    * Cliquer sur \"Download All Images\" (le plugin du navigateur)\n",
    "    * Dézipper le fichier téléchargé\n",
    "    * Récupérer seulement des images pertinentes\n",
    "    * Mettre ces images dans votre arboscence:\n",
    "        \"img/<nom_de_l_equipe>/<un_dossier_par_catégorie>/*.png\"\n",
    "    * Créer des matrices X et Y à partir des images:\n",
    "        * itérateur sur les dossiers et les images;\n",
    "        * chargement des images;\n",
    "        * preprocessing lié à VGG16 (ou autre modèle CNN préentrainé que vous allez utiliser);\n",
    "        * création du numpy.array finale depuis la liste des images chargés et prétraités;\n",
    "        * création du vecteur de \"labels\" à partir des noms de dossiers parcourus, pour chaque image (\"adidas adidas adidas cocacola cocacola fdj fdj fdj fdj ....\");\n",
    "        * conversion du vecteur 1-dimensionnel de labels en vecteur M-dimensionnel, où M = nombre de catégories de votre problème: pour cela, utiliser la fonction *to_categorical*. Chaque label doit donc être un vecteur avec des 0.0 et une seule valeur 1.0 sur la position qui correspond à la bonne catégorie.\n",
    "        \n",
    "3. Utiliser un des modèles CNN (convolutional neural network) déjà entrainé (comme VGG ou autre, cf. ici https://keras.io/applications/) pour faire des prédictions sur quelques images de votre dataset. Utiliser \"decode_predictions\" pour afficher à quelles classes appartient des valeurs maximales du vecteur de prédiction\n",
    "\n",
    "* Comme votre use case est spécifique, et les classes présentes dans le modèle VGG ne correspondent pas à votre problème. Il faut donc faire du Transfer Learning:\n",
    "    * Prendre un modèle pré-entrainé (VGG par exemple), mais ne pas utiliser sa dernière couche! (include_top=False). Ne pas oublier de spécifier le format des images en entrée ((224, 224, 3) pour VGG). \n",
    "    * Ajouter une couche Flatten() pour aplaitir la matrice pour obtenir le vecteur 1-dimensionnel.\n",
    "    * Ajouter une couche Dense(nb_classes, activation=\"softmax\")\n",
    "    * Créer un modele *custom* qui va utiliser ces couches-là.\n",
    "    * Comme le modèle VGG sera en version \"cut\" (\"truncated\"), donc elle ne sera pas utilisé pour les prédictions mais seulement pour extraction de features. Donc, il faut préciser que les couches du modèle custom soit déclarés comme \"layer.trainable = False\". Utiliser l'itérateur sur \"custom_model.layers\" afin de préciser quelles couches ne pas entrainer.\n",
    "    * Vérifier avec \"custom_model.summary()\" que seulement les paramètres qui correspondent à la dernière couche Dense seront entrainés (cf. les messages \"Total parameters, Trainable parameters, Non-Trainable parameters\" du summary.\n",
    "    * Déclarer la méthod de \"compilation\" du modèle (fonction de perte, algorithme, métrique) avec \"custom_model.compile(....)\"\n",
    "    * Finalement, ENTRAINER le modèle avec la commande \"custom_modèle.fit\". Utiliser plusieurs nombre de *epochs* (plus est mieux, quitte à laisser le modèle s'entrainer pendant plusieurs heures); varier le *batch_size* en fonction de nombre totale d'images dans votre dataset (batch_size plus élevé accélère l'entrainement mais dégrade le résultat; par contre valeur 1 risque de finir par le \"overfit\", \"surapprentissage\", où le modèle va apprendre par coeur des exemple, mais mal généraliser sur des nouvelles images, donc le score sera mauvais aussi. Trouver la bonne valeur de batch_size, commenter les étapes de votre expérimentation.\n",
    "    \n",
    "    \n",
    "* Charger des images depuis le dossier \"img/test_images\", utiliser le même prétraitement afin d'avoir le même format que des matrices X (pas besoin de Y ici, car vous allez juste lancer des prédictions).\n",
    "* Lancer des prédictions sur ces nouvelles images (custom_model.predict).\n",
    "* Interpréter des prédictions. Quelle catégorie donne la proba maximale?  Afficher l'image dans notebook pour voir ce qu'elle représente. Est-ce que c'est la bonne catégorie qui a été prédite?\n",
    "\n",
    "\n",
    "#### Faire un résumé du projet: qu'est-ce que vous avez fait, quels résultats obtenus. Quel score a votre modèle, est-ce qu'elle prédit bien sur des images de test.\n",
    "#### Commentez votre code!!! \n",
    "    \n",
    "### livrables: GITHUB!!! code + images, la même arborescence que dl \n",
    "### denis.lazarenko@gmail.com\n",
    "~~deadline: 3 mars 2019 , 23:59:59~~\n",
    "\n",
    "désolé d'avoir envoyé une mauvaise version du fichier vendredi dernier\n",
    "\n",
    "on va donc avancer la deadline\n",
    "### deadline: 10 mars 2019 , 23:59:59\n",
    "### questions  par mail ou slack\n",
    "\n",
    "\n",
    "#### Liens utils\n",
    "* training Keras models: \n",
    "  https://keras.io/getting-started/sequential-model-guide/\n",
    "* deep learning tutorial: https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
    "* convolution filter produces a feature map (animation): https://www.youtube.com/watch?v=KiftWz544_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
